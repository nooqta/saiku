import Agent from "@/agents/agent";
import { PredictionRequest, PredictionResponse, LLM } from "@/interfaces/llm";
import { PredictionServiceClient, helpers, v1 } from "@google-cloud/aiplatform";
import dotenv from "dotenv";
import prompts from "prompts";

// Load environment variables from .env file
dotenv.config();
export interface FunctionCall {
  /**
   * The arguments to call the function with, as generated by the model in JSON
   * format. Note that the model does not always generate valid JSON, and may
   * hallucinate parameters not defined by your function schema. Validate the
   * arguments in your code before calling your function.
   */
  arguments: string;

  /**
   * The name of the function to call.
   */
  name: string;
}

interface GoogleVertexAILLMRequest extends PredictionRequest {
  prompt: string;
  temperature?: number;
  max_tokens?: number;
  topP?: number;
}

interface GoogleVertexAILLMResponse extends PredictionResponse {
  text: string | FunctionCall;
  model: string;
  otherMetadata?: any;
}

export class GoogleVertexAI implements LLM {
  private client: PredictionServiceClient;
  private endpoint: string;
  API_ENDPOINT: string;
  PROJECT_ID: string;
  MODEL_ID: string;
  agent: Agent;
  messages: any = [];
  name: string;
  constructor(
    agent: Agent,
    opts: {
      projectId?: string;
      apiEndpoint?: string;
      modelId?: string;
    }
  ) {
    this.agent = agent;
    const { projectId, apiEndpoint, modelId } = opts;
    this.name = modelId || "";
    this.API_ENDPOINT =
      apiEndpoint || process.env.GOOGLE_API_ENDPOINT || "us-central1";
    this.PROJECT_ID = projectId || process.env.GOOGLE_PROJECT_ID || "";
    this.MODEL_ID = modelId || process.env.GOOGLE_MODEL_ID || "text-bison";
    const clientOptions = {
      apiEndpoint: `${this.API_ENDPOINT}-aiplatform.googleapis.com`,
    };
    this.client = new v1.PredictionServiceClient(clientOptions);
    this.endpoint = `projects/${this.PROJECT_ID}/locations/us-central1/publishers/google/models/${this.MODEL_ID}`;
  }

  async predict(
    request: GoogleVertexAILLMRequest
  ): Promise<GoogleVertexAILLMResponse> {
    try {
      this.messages = this.agent.messages
      .filter((message: any) => message.role !== 'system')
      .map((message: any) => {
        return {
            content: message.content,
            author: message.role
            }
            });
      // We append the functions to the context
      const context = `
      My name is ${
        (await this.agent.sense()).agent.name
      }. I'm an agent that helps automate your tasks,\n
      You are ${JSON.stringify((await this.agent.sense()).current_user)}
      The current context is: ${JSON.stringify(await this.agent.sense())}\n
      Instructions: \n 
      I'll reply to the user request directly if I know the correct answer or I'll call one the following functions if I'm not:\n
      
            ${JSON.stringify(request.functions, null, 2)}\n
            When calling a function, I'll use the next json format and I'll replace all arguments with the actual values:\n
            Example: \n
            {\n
                "functionCall": {
                "name": "execute_code",
                "arguments": {\n  
                    "language": "{python|node|shell|applescript}",\n
                    "content": "{only valid code that answers the request here}"\n
                }\n
            }\n
            
      `;

      const prompt = {
        context,
        messages: this.messages,
        examples: [
              {
                  input: {
                    content:
                      "What is the capital of France?",
                  },
                  output: {
                    content: "The capital of France is Paris."
                  }
              },
        ],

        prompt: `${this.messages[this.messages.length - 1]?.content}`,
      };
      const instanceValue = helpers.toValue(prompt);
      const instances = [instanceValue];
      const parameter = {
        temperature: 0.2,
        topP: 0.95,
        topK: 40,
      };
      const parameters = helpers.toValue(parameter);
      // Construct request
      const predictRequest: any = {
        endpoint: this.endpoint,
        instances,
        parameters,
      };

      // Run request
      const [response] = await this.client.predict(predictRequest);
      // Extract prediction and format the response
      // @ts-ignore
      // @ts-ignore
      let { candidates } = helpers.fromValue(response.predictions[0]);
      let prediction = candidates[0].content;
      if (!prediction) {
          throw new Error("No predictions returned from the model.");
        }
        
      const languageMatch = prediction.match(/```(\w*)/);
      if (prediction && languageMatch && !prediction.includes("functionCall")) {
        // We need to extract language and content from the code snippet
        const language = (languageMatch && languageMatch[1]) || "python";
        const content = prediction
          .replace(/```(\w*)/g, "")
          .replace(/\`\`\`/g, "");

        const jsonData = {
          functionCall: {
            name: "execute_code",
            arguments: {
              language: language,
              content: content,
            },
          },
        };

        prediction = JSON.stringify(jsonData, null, 2);
      }

      // tweak to sanitize the response as we need a valid JSON format to be able to parse it. We extract the functionCall object only if there is one otherwise we return the content
      prediction = prediction?.replace(/\`\`\`\w*/g, "").replace(/\`\`\`/g, "");
      try {
        prediction = JSON.parse(prediction);
        if (prediction.functionCall) {
          prediction = prediction.functionCall;
        }
      } catch (error) {
        // Silently ignore the error
      }

      return {
        text: prediction,
        model: this.MODEL_ID,
      };
    } catch (error) {
      console.error(`An error occurred: ${error}`);
      throw error;
    }
  }

  async interact(): Promise<void> {
    const decision = await this.agent.think();

    const functionCall = typeof decision.text !== 'string'? decision.text: null;
    const content = typeof decision.text === 'string'? decision.text: null;

    if (content) {
      this.agent.messages.push({
        role: "assistant",
        content,
      });

      // Remove speech output logic
      // if(['both', 'output'].includes(this.agent.options.speech || 'none')) {
      //   await this.agent.speak(content, true);
      // }
      this.agent.displayMessage(content);
    } else {
      let actionName = functionCall?.name ?? "";
      let args = functionCall?.arguments ?? "";
      let result: any = "";
      // We avoid executing if the last action is the same as the current action
      if (this.agent.memory.lastAction === actionName && this.agent.memory.lastActionStatus === 'failure') {
        this.agent.updateMemory({
          lastAction: null,
          lastActionStatus: null,
        });
        return;
      }
      try {
        args = functionCall?.arguments && typeof functionCall?.arguments == 'string' ?JSON.parse(functionCall?.arguments ?? ""): functionCall?.arguments ?? "";
        if(!this.agent.options.allowCodeExecution) {
          // request to execute code
          const { answer } = await prompts({
            type: "confirm",
            name: "answer",
            message: `Do you want to execute the code?`,
            initial: true
          });
          if(!answer) {
            result = "Code execution cancelled for current action only";
          } else {
            result = await this.agent.act(actionName, args);
          }
        } else {
          result = await this.agent.act(actionName, args);
        }
      } 
      catch (error) {
        result = JSON.stringify(error);
      }
 
      this.agent.messages.push({
        role: "assistant",
        content: result, 
      });

      this.agent.displayMessage(result);
    }
  }
}
